{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Introduction to Web-Scraping</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method of collecting data from websites is called Web Scraping. Usually the software or the script that does this process is termed as `Bot` or `Web Crawler`.\n",
    "\n",
    "* Web Harvesting\n",
    "* Web Data Extraction\n",
    "* Screen Scraping\n",
    "* Growth Hacking\n",
    "\n",
    "**Usual Ways**\n",
    "\n",
    "* Collecting data from online and storing it in your local file or database.\n",
    "* Collecting data from online and deploying it as an API or URL for further usages.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/960/0*9PbNnwHdp8ocBn7b.jpg\">\n",
    "\n",
    "**Credit** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* API - (Application Programing Interface) acts as a mediator between server and the client machine.\n",
    "    - Imagine API to be a URL (link) in which the data is obtained by slightly changing the behaviour.\n",
    "    - Client (User) requests for the data from the server through API.\n",
    "    - Server responds the user if the request is valid (success - status code â†’ 200)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Web Scraping and Hacking</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping is often termed as a growth hacking technique to build up sales pipeline and determine how the competitors are setting their prices for the similar products. \n",
    "\n",
    "Well that comes under marketing field. How is data science and coding related to web scraping.\n",
    "\n",
    "**More information** - https://www.entrepreneur.com/article/296906\n",
    "\n",
    "Web scraping is used to collect the data which is publicly open. It helps so many businesses in so many ways -\n",
    "\n",
    "* To understad the customer behaviour.\n",
    "* To estimate or understand what the customer is craving for.\n",
    "* To make machine learning model **from the public data** and predict the customer interest.\n",
    "* so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is web scraping legal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two dimensions here as well\n",
    "\n",
    "* Good Bots\n",
    "* Bad Bots\n",
    "\n",
    "**Good Bots** - They value the owner's standards and abide with the rules of scraping. They value the customers point in knowing more with less effort like `price comparison`, `social sentiment guaging`, `helping market researchers` and other so many aspects.\n",
    "\n",
    "**Bad Bots** - Very much opposite to `Good Bots`. Data Breach, User account hacking, Online Fraud, Unauthorized vulnerability scans, Spam and digital ad fraud.\n",
    "\n",
    "![gb_bots](https://user-images.githubusercontent.com/63333753/126785454-592335c1-6e99-4378-a041-d4c7fa389c02.PNG)\n",
    "\n",
    "<center>Bad Bot <strong> vs </strong> Good Bot</center>\n",
    "\n",
    "**Credits** - Image from Internet\n",
    "\n",
    "<br>\n",
    "Web scraping is not illegal after all. Startups love web scraping to understand customers and they are getting the data without much effort in partnering with other data providers.\n",
    "\n",
    "**More information** - https://www.imperva.com/blog/is-web-scraping-illegal/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Web Scraping in Python</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web scraping in python can be done using the following packages.\n",
    "\n",
    "* requests\n",
    "* bs4\n",
    "* selenium - requires chromium or firefox driver\n",
    "* scrapy\n",
    "\n",
    "<img src=\"https://www.scrapingbee.com/images/post/python-101/python_101_cover.jpg\">\n",
    "\n",
    "**Credits** - Image from Internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of the Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Windows - open command prompt\n",
    "\n",
    "* **bs4** - `py -m pip install bs4 --user`\n",
    "* **requests** - `py -m pip install requests --user`\n",
    "\n",
    "For Linux - open terminal\n",
    "\n",
    "* **bs4** - `pip install bs4 --user`\n",
    "* **requests** - `pip install requests --user`\n",
    "\n",
    "But before doing this, make sure your `pip` is recognized in Windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Live coding</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**JSON** - JavaScript Object Notation\n",
    "\n",
    "* lightweigt data interchange format\n",
    "* easy for humans to read\n",
    "* extraction is done by parsing method\n",
    "* it can be taken as a dictionary in python\n",
    "\n",
    "**Struncture of JSON**\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"key\" : \"value\",\n",
    "    \"key\" : {\n",
    "        \"sub_key\" : \"value\",\n",
    "        \"sub_key\" : \"value\"\n",
    "    },\n",
    "    \"key\" : [\n",
    "        {\n",
    "            \"sub_key\" : \"value\",\n",
    "            \"sub_key\" : \"value\"\n",
    "        }, \n",
    "        {\n",
    "            \"sub_key\" : \"value\",\n",
    "            \"sub_key\" : \"value\"\n",
    "        }\n",
    "    ],\n",
    "    \"key\" : \"value\",\n",
    "    \"key\" : [\"value\", \"value\", \"value\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scrape the device location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ip_url = 'http://ip-api.com/json'\n",
    "\n",
    "import requests\n",
    "\n",
    "class DeviceTracker():\n",
    "    def __init__(self, ip_url):\n",
    "        self.ip_url = ip_url\n",
    "    \n",
    "    def get_device_data(self):\n",
    "        ip_req = requests.get(url=self.ip_url)\n",
    "        ip_data = ip_req.json()\n",
    "        return ip_data\n",
    "    \n",
    "    def get_user_loc(self):\n",
    "        ip_data = self.get_device_data()\n",
    "        city_name = ip_data['city']\n",
    "        return city_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyderabad\n"
     ]
    }
   ],
   "source": [
    "ip_url = 'http://ip-api.com/json'\n",
    "ip_dev = DeviceTracker(ip_url=ip_url)\n",
    "city_name = ip_dev.get_user_loc()\n",
    "print(city_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's scrape the location of any place and get the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 'http://api.openweathermap.org/data/2.5/weather?q={}&appid=9d41bd4e5bffd04e03a6cb6832066559'\n",
    "# name - anything\n",
    "# celsius - temp - 273\n",
    "# farenheit - celsius * 9/5 + 32\n",
    "\n",
    "import requests\n",
    "\n",
    "class WeatherApp(DeviceTracker):\n",
    "    def __init__(self, ip_url):\n",
    "        self.ip_url = ip_url\n",
    "        self.weather_url = 'http://api.openweathermap.org/data/2.5/weather?q={}&appid=9d41bd4e5bffd04e03a6cb6832066559'\n",
    "        self.place_name = None\n",
    "    \n",
    "    def get_weather_data(self):\n",
    "        self.place_name = input(\"Please enter valid city name: \")\n",
    "        w_url = self.weather_url.format(self.place_name)\n",
    "        w_req = requests.get(url=w_url)\n",
    "        \n",
    "        if (w_req.status_code == 200):\n",
    "            w_data = w_req.json()\n",
    "        else:\n",
    "            print(\"-----------------\")\n",
    "            print(\"The entered place name is not valid\")\n",
    "            print(\"Getting the user location ...\")\n",
    "            self.place_name = self.get_user_loc()\n",
    "            w_url = self.weather_url.format(self.place_name)\n",
    "            w_req = requests.get(url=w_url)\n",
    "            w_data = w_req.json()\n",
    "        \n",
    "        return w_data\n",
    "    \n",
    "    def get_parsed_details(self):\n",
    "        w_data = self.get_weather_data()\n",
    "        \n",
    "        desc = w_data['weather'][0]['description']\n",
    "        temp = w_data['main']['temp']\n",
    "        humidity = w_data['main']['humidity']\n",
    "        wind_speed = w_data['wind']['speed']\n",
    "        all_clouds = w_data['clouds']['all']\n",
    "        \n",
    "        celsius = temp - 273\n",
    "        farenheit = (celsius * (9 / 5)) + 32\n",
    "        \n",
    "        print(\"-----------------\")\n",
    "        print(\"The weather details of the place - {}\".format(self.place_name))\n",
    "        print(\"Weather description - \", desc)\n",
    "        print(\"The temp in celsius - \", round(celsius, 2))\n",
    "        print(\"The temp in farenheit - \", round(farenheit, 2))\n",
    "        print(\"The wind speed - {} mpg\".format(wind_speed))\n",
    "        print(\"Humidity - \", humidity)\n",
    "        print(\"Total clouds - \", all_clouds)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter valid city name: lucknow\n",
      "-----------------\n",
      "The weather details of the place - lucknow\n",
      "Weather description -  haze\n",
      "The temp in celsius -  29.14\n",
      "The temp in farenheit -  84.45\n",
      "The wind speed - 1.03 mpg\n",
      "Humidity -  89\n",
      "Total clouds -  75\n"
     ]
    }
   ],
   "source": [
    "ip_url = 'http://ip-api.com/json'\n",
    "w_app = WeatherApp(ip_url=ip_url)\n",
    "w_app.get_parsed_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What did we learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Web scraping definition\n",
    "* Bot and crawlers\n",
    "* Web scraping and Growth hacking\n",
    "* Web scraping legal/illegal\n",
    "* Live coding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
